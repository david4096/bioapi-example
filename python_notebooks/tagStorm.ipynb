{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagstorm as GA4GH Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GA4GH dataset message allows data regarding some topic of concern to be grouped and is a natural place to provide top level metadata for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will show how the GA4GH schemas can be used to interchange tagstorm metadata in a dataset message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GA4GH Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ga4gh.schemas.ga4gh import metadata_pb2 as metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protocol buffers provides a language neutral representation that can be serialized as binary or JSON. We begin by importing the schemas and initializing an empty dataset message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = metadata.Dataset()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate basic features of the message, we first set it's name. Datasets are also expected to have a unique identifier for any server instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"Tag Storm Test\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.name = \"Tag Storm Test\"\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The info field was designed to allow arbitrary data to be interchanged and is organized as a map of string to lists. A proposal has been made to improve type representation in the field [here](https://github.com/ga4gh/schemas/pull/700). However, for the string-string mappings the info field should suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.attributes)\n",
    "attributes = dataset.attributes.attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently this field isn't set. Let's add a test attribute key that will be a mapping of a string to a single string. Remember, we are acting on language neutral protobuf objects here, although the syntax may borrow from the python API, they are not python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.attributes.attr['tagStorm'].values.add().string_value = \"version 0.0\"\n",
    "tagStorm = dataset.attributes.attr['tagStorm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"Tag Storm Test\"\n",
      "attributes {\n",
      "  attr {\n",
      "    key: \"tagStorm\"\n",
      "    value {\n",
      "      values {\n",
      "        string_value: \"version 0.0\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simplest use case, our resulting structure is a bit overwrought. The `value` and `values` fields are the indirection that allow us to define our own type system, which protobuf serializers and deserializers will handle by default.\n",
    "\n",
    "We can add more values to this key using the same method as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values {\n",
      "  string_value: \"version 0.0\"\n",
      "}\n",
      "values {\n",
      "  string_value: \"test\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagStorm.values.add().string_value = \"test\"\n",
    "print(tagStorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that types under a key do not have to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values {\n",
      "  string_value: \"version 0.0\"\n",
      "}\n",
      "values {\n",
      "  string_value: \"test\"\n",
      "}\n",
      "values {\n",
      "  int64_value: 31412412549823242\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagStorm.values.add().int64_value = 31412412549823242\n",
    "print(tagStorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing tagStorm data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tagStorm is a no-markup language for describing genomics metadata. First, we'll get the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "#response = urllib2.urlopen(\"http://hgwdev.cse.ucsc.edu/~kent/tagStorm/testTagStorm.txt\")\n",
    "response = urllib2.urlopen(\"https://gist.githubusercontent.com/david4096/93483758c6519ed9d5e0e6888af1b566/raw/df11db57fac290585dd0c2efe22de8fc698fadcf/tagStorm.txt\")\n",
    "tagStormdata = response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll print out some to observe the file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab smith\n",
      "assay RNA-seq\n",
      "access all\n",
      "organ brain\n",
      "\n",
      "    donor 002\n",
      "    age 5\n",
      "    age_units weeks\n",
      "    life_stage embryo\n",
      "    sex male\n",
      "    biosample_date 2015-01-05\n",
      "\n",
      "        organ brain\n",
      "        lab_smith_disassociation_protocol fetal_brain_digest.pdf\n",
      "        lab_smith_quality 0\n",
      "\n",
      "            part 1\n",
      "            format fastq\n",
      "            file ex00do00or00fa00.fq.gz\n",
      "\n",
      "            file ex00do00or00fa01.fq.gz\n",
      "            format fastq\n",
      "            part 2\n",
      "\n",
      "            file ex00do00or00fa02.fq.gz\n",
      "            format\n"
     ]
    }
   ],
   "source": [
    "print(tagStormdata[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that this is a hierarchical data structure that uses indentation. Order seems to be important, and there seems to be no restriction on the types of nodes that can have children. \n",
    "\n",
    "Unfortunately, protobuf maps require the keys to be strings, integers, or boolean. The tagStorm structure allows arbitrary ordered lists of key-value pairs to act as keys to nested nodes. To interchange this data structure with the proper fidelity, we'll have to create our own key: `children`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing tagStorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interchange tagStorm, we create a hierarchical structure of attributes, using a `children` key. Let's create a simple tagStorm structure with a two tag stanza and one nested stanza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values {\n",
      "  attributes {\n",
      "    attr {\n",
      "      key: \"assay\"\n",
      "      value {\n",
      "        values {\n",
      "          string_value: \"RNA-Seq\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    attr {\n",
      "      key: \"children\"\n",
      "      value {\n",
      "        values {\n",
      "          attribute_list {\n",
      "            values {\n",
      "              attributes {\n",
      "                attr {\n",
      "                  key: \"donor\"\n",
      "                  value {\n",
      "                    values {\n",
      "                      string_value: \"002\"\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    attr {\n",
      "      key: \"lab\"\n",
      "      value {\n",
      "        values {\n",
      "          string_value: \"smith\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "values {\n",
      "  attributes {\n",
      "    attr {\n",
      "      key: \"assay\"\n",
      "      value {\n",
      "        values {\n",
      "          string_value: \"RNA-Seq\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    attr {\n",
      "      key: \"lab\"\n",
      "      value {\n",
      "        values {\n",
      "          string_value: \"doe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = metadata.Dataset()\n",
    "# Make a list of attributes that will be the root of the tag tree\n",
    "tagStorm = dataset.attributes.attr['tagStorm'].values.add().attribute_list\n",
    "# Make a node that will have some attributes\n",
    "node = tagStorm.values.add().attributes\n",
    "node.attr[\"lab\"].values.add().string_value = \"smith\"\n",
    "node.attr[\"assay\"].values.add().string_value = \"RNA-Seq\"\n",
    "node2 = tagStorm.values.add().attributes\n",
    "node2.attr[\"lab\"].values.add().string_value = \"doe\"\n",
    "node2.attr[\"assay\"].values.add().string_value = \"RNA-Seq\"\n",
    "children = node.attr[\"children\"].values.add().attribute_list.values\n",
    "childnode = children.add().attributes\n",
    "childnode.attr['donor'].values.add().string_value = \"002\"\n",
    "print(tagStorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a combination of attributes and attribute value lists the GA4GH schemas can interchange tagstorm data, with the added benefit of type security on values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assay RNA-Seq\n",
      "lab smith\n",
      "\n",
      "    donor 002\n",
      "\n",
      "assay RNA-Seq\n",
      "lab doe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def proto_to_tagstorm(message, indent=0):\n",
    "    lines = []\n",
    "    for v in message.values:\n",
    "        for node in v.attribute_list.values:\n",
    "            children = []\n",
    "            for key in node.attributes.attr:\n",
    "                if key != 'children':\n",
    "                    value = node.attributes.attr[key].values[0].string_value\n",
    "                    lines.append(\"{indent}{key} {value}\".format(\n",
    "                            indent=indent * \"    \", key=key, value=value))\n",
    "                else:\n",
    "                    children = proto_to_tagstorm(node.attributes.attr[key], indent=(indent+1))\n",
    "            lines.append(\"\")\n",
    "            lines = lines + children\n",
    "    return lines\n",
    "\n",
    "for line in proto_to_tagstorm(dataset.attributes.attr['tagStorm']):\n",
    "    print line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since tag storm files appear to not maintain type information, the above code should be able to be create tagStorm files from properly formatted attribute lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing tagStorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a simple parser that will read the tagStorm file line by line. By counting the indentation level and splitting each line, we can create a dictionary that represents the tagStorm. We will assume that space-based indentation is used, that the first line has no indentation, and that the first space on a line is always the key-value separator. Extra empty new lines are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assay RNA-Seq\n",
      "lab smith\n",
      "\n",
      "\n",
      "    donor 002\n",
      "\n",
      "assay RNA-Seq\n",
      "lab doe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tagstorm_to_proto(tagstorm):\n",
    "    #print('converting')\n",
    "    lastindent = 0\n",
    "    dataset = metadata.Dataset()\n",
    "    current = dataset.attributes.attr['tagStorm'].values.add().attribute_list\n",
    "    i = 0\n",
    "    roots = []\n",
    "    roots.append(current)\n",
    "    node = current.values.add().attributes\n",
    "    while i < len(tagstorm):\n",
    "        line = tagstorm[i]\n",
    "        indentation = (len(line) - len(line.lstrip())) / 4 # spaces\n",
    "        line = line.lstrip()\n",
    "        if indentation > lastindent and line:\n",
    "            node = current.values.add().attributes\n",
    "            roots.append(current)\n",
    "            current = node.attr['children'].values.add().attribute_list\n",
    "            lastindent = indentation\n",
    "        elif indentation < lastindent and line:\n",
    "            for k in range(lastindent - indentation):\n",
    "                if len(roots) > 0:\n",
    "                    current = roots.pop()\n",
    "            lastindent = indentation\n",
    "        elif indentation == lastindent and line:\n",
    "            if len(roots) < indentation:\n",
    "                roots.append(current)\n",
    "        # read a stanza\n",
    "        #print('adding stanza starting with', line)\n",
    "        node = current.values.add().attributes\n",
    "        while len(line) != 0 and i < len(tagstorm):\n",
    "            key, value = line.split(' ')[0], \"\".join(line.split(' ')[1:])\n",
    "            node.attr[key].values.add().string_value = value\n",
    "            i += 1\n",
    "            line = tagstorm[i]\n",
    "            line = line.lstrip()\n",
    "        i += 1\n",
    "        # end of a stanza\n",
    "    return dataset\n",
    "\n",
    "# convert back and forth using the above function\n",
    "for line in proto_to_tagstorm(\n",
    "    tagstorm_to_proto(\n",
    "        proto_to_tagstorm(\n",
    "            dataset.attributes.attr['tagStorm'])).attributes.attr['tagStorm']):\n",
    "    print line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Parse a tagstorm file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have the mechanisms to interchange tagStorm data in GA4GH attribute lists, we can process the file downloaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "access all\n",
      "assay RNA-seq\n",
      "organ brain\n",
      "lab smith\n",
      "\n",
      "\n",
      "    age_units weeks\n",
      "    age 5\n",
      "    life_stage embryo\n",
      "    sex male\n",
      "    biosample_date 2015-01-05\n",
      "    donor 002\n",
      "\n",
      "\n",
      "        lab_smith_quality 0\n",
      "        lab_smith_disassociation_protocol fetal_brain_digest.pdf\n",
      "        organ brain\n",
      "\n",
      "\n",
      "            part 1\n",
      "            file ex00do00or00fa00.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            part 2\n",
      "            file ex00do00or00fa01.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            part 3\n",
      "            file ex00do00or00fa02.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            file ex00do00or00.bam\n",
      "            format bam\n",
      "\n",
      "\n",
      "        lab_smith_quality 0.01\n",
      "        lab_smith_disassociation_protocol fetal_liver_digest.pdf\n",
      "        organ liver\n",
      "\n",
      "\n",
      "            part 1\n",
      "            file ex00do00or01fa00.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            part 2\n",
      "            file ex00do00or01fa01.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            file ex00do00or01.bam\n",
      "            format bam\n",
      "\n",
      "    age_units weeks\n",
      "    age 6\n",
      "    life_stage embryo\n",
      "    sex male\n",
      "    biosample_date 2015-01-09\n",
      "    donor 005\n",
      "\n",
      "\n",
      "        lab_smith_quality 0.04\n",
      "        lab_smith_disassociation_protocol fetal_liver_digest.pdf\n",
      "        organ liver\n",
      "\n",
      "\n",
      "            part 1\n",
      "            file ex00do00or02fa00.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            part 2\n",
      "            file ex00do00or02fa01.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            part 3\n",
      "            file ex00do00or02fa02.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            file ex00do00or02.bam\n",
      "            format bam\n",
      "\n",
      "\n",
      "access all\n",
      "assay RNA-seq\n",
      "organ brain\n",
      "lab zhen\n",
      "\n",
      "\n",
      "    age_units weeks\n",
      "    age 5\n",
      "    life_stage embryo\n",
      "    sex male\n",
      "    biosample_date 2015-08-05\n",
      "    donor 101\n",
      "    lab_zhen_sample_notes 1houranoxic\n",
      "\n",
      "\n",
      "        organ brain\n",
      "\n",
      "\n",
      "            file ex01do00or00fa00.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            file ex01do00or00.bam\n",
      "            format bam\n",
      "\n",
      "        organ liver\n",
      "\n",
      "\n",
      "            part 1\n",
      "            file ex01do00or01fa00.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            part 2\n",
      "            file ex01do00or01fa01.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            part 3\n",
      "            file ex01do00or01fa02.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            file ex01do00or01.bam\n",
      "            format bam\n",
      "\n",
      "    age_units weeks\n",
      "    age 6\n",
      "    life_stage embryo\n",
      "    sex male\n",
      "    biosample_date 2015-08-10\n",
      "    donor 103\n",
      "    lab_zhen_sample_notes cysticfibrosisgenotype\n",
      "\n",
      "\n",
      "        organ brain\n",
      "        format fastq\n",
      "\n",
      "\n",
      "            part 1\n",
      "            file ex01do00or00fa00.fq.gz\n",
      "\n",
      "            part 2\n",
      "            file ex01do00or00fa01.fq.gz\n",
      "\n",
      "            part 3\n",
      "            file ex01do00or00fa02.fq.gz\n",
      "\n",
      "            part 4\n",
      "            file ex01do00or00fa03.fq.gz\n",
      "\n",
      "        organ liver\n",
      "\n",
      "\n",
      "            part 1\n",
      "            file ex01do00or02fa00.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            part 2\n",
      "            file ex01do00or02fa01.fq.gz\n",
      "            format fastq\n",
      "\n",
      "            file ex01do00or02.bam\n",
      "            format bam\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(tagStormdata[0:500])\n",
    "#print(tagstorm_to_proto(\n",
    " #           tagStormdata.split(\"\\n\")).attributes.attr['tagStorm'])\n",
    "for line in proto_to_tagstorm(\n",
    "        tagstorm_to_proto(\n",
    "            tagStormdata.split(\"\\n\")).attributes.attr['tagStorm']):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that although the order of stanzas are preserved, order of keys are not preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've read all the way to the here, you might head over to [the pull request on the schemas](https://github.com/ga4gh/schemas/pull/700) to give this feature more community visibility and lend your support.\n",
    "\n",
    "Future directions would include providing a tagstorm-to-GA4GH parser with the reference server's data ingestion methods. This would allow tagstorm files to be provided for any message.\n",
    "\n",
    "If all of the metadata for a dataset are collected in a single file, as was shown here, curators might provide the entire tagstorm on the dataset. This would allow clients to quickly create attribute indexes of datasets that can assist with organizing inquiries into the underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
